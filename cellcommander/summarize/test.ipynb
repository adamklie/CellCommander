{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "import cellcommander\n",
    "import scanpy as sc\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_qc_log_data(log_data, markdown_text):\n",
    "    markdown_text += \" - Filtered initial cells with < 20 genes\\n\"\n",
    "    for line in log_data:\n",
    "        if \"Low nfeatures threshold\" in line:\n",
    "            to_add = line.split(\"INFO - \")[1].strip() + \"\\n\"\n",
    "            markdown_text += \" - \" + to_add\n",
    "        if \"High nfeatures threshold\" in line:\n",
    "            to_add = line.split(\"INFO - \")[1].strip() + \"\\n\"\n",
    "            markdown_text += \" - \" + to_add\n",
    "        if \"Percent counts in MT threshold\" in line:\n",
    "            to_add = line.split(\"INFO - \")[1].strip() + \"\\n\"\n",
    "            markdown_text += \" - \" + to_add\n",
    "        if \"Number of cells after filtering of low quality cells:\" in line:\n",
    "            to_add = line.split(\"Number of cells after filtering of low quality cells:\")[1].strip()\n",
    "            markdown_text += \" - Retained \" + to_add + \" cells\\n\"\n",
    "    markdown_text += \" - No gene filtering\\n\\n\"\n",
    "    return markdown_text\n",
    "\n",
    "\n",
    "def add_qc_images(input_dir, outdir_path, markdown_text):\n",
    "    # Add image to markdown, make sure it's centered\n",
    "    if os.path.exists(os.path.join(input_dir, \"total_counts_vs_n_genes_after_qc.png\")):\n",
    "        os.system(f\"cp {os.path.join(input_dir, 'total_counts_vs_n_genes_after_qc.png')} {outdir_path}\")\n",
    "        image_caption = \"Plot of total counts vs number of genes after QC colored by mitochondrial count percentage. These should correspond \" \\\n",
    "                        \"to the thresholds listed\"\n",
    "        html_text = f\"<p align=\\\"center\\\"><img src=\\\"total_counts_vs_n_genes_after_qc.png\\\" width=\\\"500\\\"><br>{image_caption}</p>\\n\\n\"\n",
    "        markdown_text += html_text\n",
    "    return markdown_text\n",
    "\n",
    "\n",
    "def write_remove_background_log_data(log_data, markdown_text):\n",
    "    # Add markers that were used\n",
    "    for line in log_data:\n",
    "        if \"Reading in SoupX markers from\" in line:\n",
    "            to_add = line.split(\"INFO - Reading in SoupX markers from\")[1].strip()\n",
    "            markdown_text += \" - SoupX markers: `\" + to_add + \"`\\n\\n\"\n",
    "    return markdown_text\n",
    "\n",
    "\n",
    "def add_remove_background_images(input_dir, outdir_path, markdown_text):\n",
    "    # Add image to markdown, make sure it's centered\n",
    "    if os.path.exists(os.path.join(input_dir, \"initial_soupx_groups_umap.png\")):\n",
    "        os.system(f\"cp {os.path.join(input_dir, 'initial_soupx_groups_umap.png')} {outdir_path}\")\n",
    "        image_caption = \"UMAP of data fed into SoupX with initial clustering of cells. \" \\\n",
    "            \"This clustering is used by SoupX to inform background removal. See the method page for more details. \" \\\n",
    "            \"The UMAP plot is generated after shifted logarithm normalization, subsetting down to HVGs and running PCA with ScanPy. \" \\\n",
    "            \"Leiden clustering performed with 30 neighbors, 50 components and a resolution of 0.5.\\n\\n\"\n",
    "        html_text = f\"<p align=\\\"center\\\"><img src=\\\"initial_soupx_groups_umap.png\\\" width=\\\"500\\\"><br>{image_caption}</p>\\n\\n\"\n",
    "        markdown_text += html_text\n",
    "    return markdown_text\n",
    "\n",
    "\n",
    "def write_doublet_detection_log_data(log_data, markdown_text):\n",
    "    # Add markers that were used\n",
    "    methods_used = []\n",
    "    used_cellranger = True\n",
    "    cells_retained = None\n",
    "    for line in log_data:\n",
    "        if \"Running\" in line and \"for doublet detection\" in line:\n",
    "            method = line.split(\"Running \")[1].split(\" for doublet detection\")[0]\n",
    "            methods_used.append(method)\n",
    "    markdown_text += \" - Called doublets with \" + \", \".join(methods_used) + \"\\n\"\n",
    "    if used_cellranger:\n",
    "        markdown_text += \" - Filtered out CellRanger called doublets\\n\"\n",
    "    if cells_retained:\n",
    "        markdown_text += \" - \" + cells_retained + \" retained\\n\\n\"\n",
    "    else:\n",
    "        markdown_text += \" - No doublet filtering reported\\n\\n\"\n",
    "    return markdown_text\n",
    "\n",
    "\n",
    "def add_doublet_detection_images(input_dir, outdir_path, markdown_text):\n",
    "    # Add image to markdown, make sure it's centered\n",
    "    if os.path.exists(os.path.join(input_dir, \"doublet_leiden_scores_umap.png\")):\n",
    "        os.system(f\"cp {os.path.join(input_dir, 'doublet_leiden_scores_umap.png')} {outdir_path}\")\n",
    "        image_caption = \"UMAPs with doublet scores from all methods used overlayed. These UMAP plots is generated after shifted logarithm normalization, \" \\\n",
    "            \"subsetting down to HVGs and running PCA with ScanPy. Leiden clustering performed with 30 neighbors, 50 components and a resolution of 0.5.\\n\\n\"\n",
    "        html_text = f\"<p align=\\\"center\\\"><img src=\\\"doublet_leiden_scores_umap.png\\\" width=\\\"1500\\\"><br>{image_caption}</p>\\n\\n\"\n",
    "        markdown_text += html_text\n",
    "    return markdown_text\n",
    "\n",
    "\n",
    "def write_normalization_log_data(log_data, markdown_text):\n",
    "    # Add markers that were used\n",
    "    methods_used = []\n",
    "    genes_filtered = False\n",
    "    for line in log_data:\n",
    "        if \"Running\" in line and \"normalization\" in line:\n",
    "            method = line.split(\"Running \")[1].split(\" normalization\")[0]\n",
    "            methods_used.append(method)\n",
    "        if \"Number of genes after cell filter:\" in line:\n",
    "            genes_filtered = True\n",
    "            to_add = line.split(\"Number of genes after cell filter:\")[1].strip()\n",
    "    markdown_text += \" - Normalized with \" + \", \".join(methods_used) + \"\\n\"\n",
    "    if genes_filtered:\n",
    "        markdown_text += \" - Retained \" + to_add + \" genes\\n\\n\"\n",
    "    else:\n",
    "        markdown_text += \" - No gene filtering\\n\\n\"\n",
    "    return markdown_text\n",
    "\n",
    "\n",
    "def add_normalization_images(input_dir, outdir_path, markdown_text):\n",
    "    # Add all plots that end with _distribution.png in a side by side grid, make sure it's centered\n",
    "    normalization_files = glob.glob(os.path.join(input_dir, \"*\"))\n",
    "    normalization_files = [x for x in normalization_files if x.endswith(\"_distribution.png\")]\n",
    "    normalization_files = [x for x in normalization_files if \"unnormalized_total_counts_distribution.png\" not in x]\n",
    "    normalization_files = [x for x in normalization_files if \"depth_normalization_distribution.png\" not in x]\n",
    "    html_text = \"\"\n",
    "    for file in normalization_files:\n",
    "        os.system(f\"cp {file} {outdir_path}\")\n",
    "        html_text += f\"<img src=\\\"{os.path.basename(file)}\\\" width=\\\"600\\\">\"\n",
    "    html_text += \"\\n\\n\"\n",
    "    markdown_text += html_text\n",
    "    return markdown_text\n",
    "\n",
    "\n",
    "def write_feature_selection_log_data(log_data, markdown_text):\n",
    "    # Add markers that were used\n",
    "    methods_used = []\n",
    "    for line in log_data:\n",
    "        if \"Running\" in line and \"feature selection\" in line:\n",
    "            method = line.split(\"Running \")[1].split(\" feature selection\")[0]\n",
    "            methods_used.append(method)\n",
    "    markdown_text += \" - Selected features with \" + \", \".join(methods_used) + \"method\\n\\n\"\n",
    "    return markdown_text\n",
    "\n",
    "\n",
    "def add_feature_selection_images(input_dir, outdir_path, markdown_text):\n",
    "    # Add all plots that end with .png in a side by side grid, make sure it's centered\n",
    "    feature_selection_files = glob.glob(os.path.join(input_dir, \"*\"))\n",
    "    feature_selection_files = [x for x in feature_selection_files if x.endswith(\".png\")]\n",
    "    feature_selection_files = [x for x in feature_selection_files if \"depth_normalization\" not in x]\n",
    "    html_text = \"\"\n",
    "    for file in feature_selection_files:\n",
    "        os.system(f\"cp {file} {outdir_path}\")\n",
    "        html_text += f\"<img src=\\\"{os.path.basename(file)}\\\" width=\\\"750\\\">\"\n",
    "    html_text += \"\\n\\n\"\n",
    "    markdown_text += html_text\n",
    "    return markdown_text\n",
    "\n",
    "\n",
    "def write_dimensionality_reduction_log_data(log_data, markdown_text):\n",
    "    # Add markers that were used\n",
    "    markdown_text += \" - Ran PCA on SCTransform normalized data (no feature selection needed), then UMAP on top of this. The PCA and UMAP used here were run in Seurat.\\n\"\n",
    "    markdown_text += \" - Performed an initial clustering with Leiden with 30 neighbors, 50 components (PCs) and resolution of 0.5. Implementation from Scanpy.\\n\\n\"\n",
    "    return markdown_text\n",
    "\n",
    "\n",
    "def add_dimensionality_reduction_images(input_dir, outdir_path, markdown_text):\n",
    "    # Add all plots that end with pdf, make sure it's centered\n",
    "    dimensionality_reduction_files = glob.glob(os.path.join(input_dir, \"*\"))\n",
    "    dimensionality_reduction_files = [x for x in dimensionality_reduction_files if x.endswith(\"pdf\")]\n",
    "    html_text = \"\"\n",
    "    for file in dimensionality_reduction_files:\n",
    "        os.system(f\"cp {file} {outdir_path}\")\n",
    "        image_caption = \"UMAP of SCTransform normalized data.  Leiden clustering performed with 30 neighbors, 50 components and a resolution of 0.5.\"\n",
    "        html_text += f\"<p align=\\\"center\\\"><img src=\\\"{os.path.basename(file)}\\\" width=\\\"500\\\"><br>{image_caption}</p>\\n\\n\"\n",
    "    html_text += \"\\n\\n\"\n",
    "    markdown_text += html_text\n",
    "    return markdown_text\n",
    "\n",
    "\n",
    "def write_annotate_log_data(markdown_text):\n",
    "    # Add markers that were used\n",
    "    markdown_text += \" - Use the same UMAP but plot some new clusters on it at higher resolution\\n\"\n",
    "    markdown_text += \"- In conjunction with the accompanying dot plot of known marker genes: annotation/18Oct23/SC.islet.marker_genes.csv\\n\\n\"\n",
    "    return markdown_text\n",
    "\n",
    "\n",
    "def add_annotate_images(input_dir, outdir_path, markdown_text):\n",
    "    # If annotate_clustering_umap.png in annotate directory, copy it over\n",
    "    html_text = \"\"\n",
    "    if os.path.exists(os.path.join(input_dir, \"annotate_clustering_umap.png\")):\n",
    "        os.system(f\"cp {os.path.join(input_dir, 'annotate_clustering_umap.png')} {outdir_path}\")\n",
    "        image_caption = \"UMAP of SCTransform normalized data.  Leiden clustering performed with 30 neighbors, 50 components and a resolution of 0.5.\"\n",
    "        html_text += f\"<p align=\\\"center\\\"><img src=\\\"annotate_clustering_umap.png\\\" width=\\\"500\\\"><br>{image_caption}</p>\\n\\n\"\n",
    "    # if marker_gene_dotplot.png in annotate directory, copy it over\n",
    "    if os.path.exists(os.path.join(input_dir, \"marker_gene_dotplot.png\")):\n",
    "        os.system(f\"cp {os.path.join(input_dir, 'marker_gene_dotplot.png')} {outdir_path}\")\n",
    "        image_caption = \"Dot plot of known sc islet marker genes\"\n",
    "        html_text += f\"<p align=\\\"center\\\"><img src=\\\"marker_gene_dotplot.png\\\" width=\\\"500\\\"><br>{image_caption}</p>\\n\\n\"\n",
    "    markdown_text += html_text\n",
    "\n",
    "    # if manual_cellid_annotation_umap.png in annotate directory, copy it over, center it\n",
    "    html_text = \"\"\n",
    "    if os.path.exists(os.path.join(input_dir, \"manual_cellid_annotation_umap.png\")):\n",
    "        os.system(f\"cp {os.path.join(input_dir, 'manual_cellid_annotation_umap.png')} {outdir_path}\")\n",
    "        image_caption = \"User input annotations (left) for each of the clusters defined on the right.\"\n",
    "        html_text += f\"<p align=\\\"center\\\"><img src=\\\"manual_cellid_annotation_umap.png\\\" width=\\\"1500\\\"><br>{image_caption}</p>\\n\\n\"\n",
    "    markdown_text += html_text\n",
    "    return markdown_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments\n",
    "input_dirs = [\n",
    "    \"/cellar/users/aklie/data/datasets/igvf_sc-islet_10X-Multiome/annotation/12Oct23/scanpy/H1_control/mo1\", \n",
    "    \"/cellar/users/aklie/data/datasets/igvf_sc-islet_10X-Multiome/annotation/20Oct23/cellcommander/H1_control/mo1/rna\"\n",
    "]\n",
    "ignore = []\n",
    "outdir_path = \"/cellar/users/aklie/data/datasets/igvf_sc-islet_10X-Multiome/annotation/per_sample/mo1/rna\"\n",
    "summary = \"Ran on CellRanger ARC output raw barcode x feature matrices\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cellar/users/aklie/data/datasets/igvf_sc-islet_10X-Multiome/annotation/12Oct23/scanpy/H1_control/mo1\n",
      "/cellar/users/aklie/data/datasets/igvf_sc-islet_10X-Multiome/annotation/20Oct23/cellcommander/H1_control/mo1/rna\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['remove_background',\n",
       " 'doublet_detection',\n",
       " 'feature_selection',\n",
       " 'qc',\n",
       " 'dimensionality_reduction',\n",
       " 'normalization',\n",
       " 'annotate']"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab all subcommand directories\n",
    "subcommand_dirs = []\n",
    "for input_dir in input_dirs:\n",
    "    print(input_dir)\n",
    "    subcommand_dirs += glob.glob(os.path.join(input_dir, \"*\"))\n",
    "subcommand_dirs = [x for x in subcommand_dirs if os.path.isdir(x)]\n",
    "\n",
    "# Remove ignored subcommands\n",
    "subcommand_dirs = [x for x in subcommand_dirs if os.path.basename(x) not in ignore]\n",
    "subcommand_dirs\n",
    "\n",
    "# Subcommands kept\n",
    "subcommands = [os.path.basename(x) for x in subcommand_dirs]\n",
    "subcommands"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up markdown text\n",
    "markdown_text = \"# CellCommander summary\\n\"\n",
    "\n",
    "# Add date and version\n",
    "markdown_text += \"Date: {}<br>\".format(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "markdown_text += \"CellCommander version: {}\\n\\n\".format(cellcommander.__version__)\n",
    "\n",
    "# Add summary as an <aside> tag\n",
    "markdown_text += f\"<aside class='summary'>{summary}</aside>\\n\\n\"\n",
    "\n",
    "if \"qc\" in subcommands:\n",
    "    # Get subcommand dir from index of the subcoomand\n",
    "    subcommand_dir = subcommand_dirs[subcommands.index(\"qc\")]\n",
    "\n",
    "    # Add qc heading\n",
    "    markdown_text += \"# `qc`\\n\\n\"\n",
    "\n",
    "    # List all the files in the `qc` directory\n",
    "    qc_files = glob.glob(os.path.join(subcommand_dir, \"*\"))\n",
    "\n",
    "    # Open up the file with *.log\n",
    "    log_file = [x for x in qc_files if x.endswith(\".log\")][0]\n",
    "    log_data = open(log_file).readlines()\n",
    "    \n",
    "    # Write to markdown\n",
    "    markdown_text = write_qc_log_data(log_data, markdown_text)\n",
    "    markdown_text = add_qc_images(subcommand_dir, outdir_path, markdown_text)\n",
    "\n",
    "    # Open up the anndata file \n",
    "    anndata_file = [x for x in qc_files if x.endswith(\".h5ad\")][0]\n",
    "    adata = sc.read_h5ad(anndata_file)\n",
    "    adata_obs_head = adata.obs.head()\n",
    "    markdown_text += \"The first 5 rows of the `adata.obs` dataframe:\\n\\n\"\n",
    "    markdown_text += adata_obs_head.to_markdown() + \"\\n\\n\"\n",
    "\n",
    "if \"remove_background\" in subcommands:\n",
    "    # Get subcommand dir from index of the subcoomand\n",
    "    subcommand_dir = subcommand_dirs[subcommands.index(\"remove_background\")]\n",
    "\n",
    "    # Add remove_background heading\n",
    "    markdown_text += \"# `remove_background`\\n\\n\"\n",
    "\n",
    "    # List all the files in the `remove_background` directory\n",
    "    remove_background_files = glob.glob(os.path.join(subcommand_dir, \"*\"))\n",
    "\n",
    "    # Open up the file with *.log\n",
    "    log_file = [x for x in remove_background_files if x.endswith(\".log\")][0]\n",
    "    log_data = open(log_file).readlines()\n",
    "\n",
    "    # Write to markdown\n",
    "    markdown_text = write_remove_background_log_data(log_data, markdown_text)\n",
    "    markdown_text = add_remove_background_images(subcommand_dir, outdir_path, markdown_text)\n",
    "\n",
    "if \"doublet_detection\" in subcommands:\n",
    "    # Get subcommand dir from index of the subcoomand\n",
    "    subcommand_dir = subcommand_dirs[subcommands.index(\"doublet_detection\")]\n",
    "    \n",
    "    # Add doublet_detection heading\n",
    "    markdown_text += \"# `doublet_detection`\\n\\n\"\n",
    "\n",
    "    # List all the files in the `doublet_detection` directory\n",
    "    doublet_detection_files = glob.glob(os.path.join(subcommand_dir, \"*\"))\n",
    "\n",
    "    # Open up the file with *.log\n",
    "    log_file = [x for x in doublet_detection_files if x.endswith(\".log\")][0]\n",
    "    log_data = open(log_file).readlines()\n",
    "\n",
    "    # Write to markdown\n",
    "    markdown_text = write_doublet_detection_log_data(log_data, markdown_text)\n",
    "    markdown_text = add_doublet_detection_images(subcommand_dir, outdir_path, markdown_text)\n",
    "\n",
    "if \"normalization\" in subcommands:\n",
    "    # Get subcommand dir from index of the subcoomand\n",
    "    subcommand_dir = subcommand_dirs[subcommands.index(\"normalization\")]\n",
    "\n",
    "    # Add normalization heading\n",
    "    markdown_text += \"# `normalization`\\n\\n\"\n",
    "\n",
    "    # List all the files in the `normalization` directory\n",
    "    normalization_files = glob.glob(os.path.join(subcommand_dir, \"*\"))\n",
    "\n",
    "    # Open up the file with *.log\n",
    "    log_file = [x for x in normalization_files if x.endswith(\".log\")][0]\n",
    "    log_data = open(log_file).readlines()\n",
    "\n",
    "    # Write to markdown\n",
    "    markdown_text = write_normalization_log_data(log_data, markdown_text)\n",
    "    markdown_text = add_normalization_images(subcommand_dir, outdir_path, markdown_text)\n",
    "\n",
    "if \"feature_selection\" in subcommands:\n",
    "    # Get subcommand dir from index of the subcoomand\n",
    "    subcommand_dir = subcommand_dirs[subcommands.index(\"feature_selection\")]\n",
    "\n",
    "    # Add feature_selection heading\n",
    "    markdown_text += \"# `feature_selection`\\n\\n\"\n",
    "\n",
    "    # List all the files in the `feature_selection` directory\n",
    "    feature_selection_files = glob.glob(os.path.join(subcommand_dir, \"*\"))\n",
    "\n",
    "    # Open up the file with *.log\n",
    "    log_file = [x for x in feature_selection_files if x.endswith(\".log\")][0]\n",
    "    log_data = open(log_file).readlines()\n",
    "\n",
    "    # Write to markdown\n",
    "    markdown_text = write_feature_selection_log_data(log_data, markdown_text)\n",
    "    markdown_text = add_feature_selection_images(subcommand_dir, outdir_path, markdown_text)\n",
    "\n",
    "if \"dimensionality_reduction\" in subcommands:\n",
    "    # Get subcommand dir from index of the subcoomand\n",
    "    subcommand_dir = subcommand_dirs[subcommands.index(\"dimensionality_reduction\")]\n",
    "\n",
    "    # Add dimensionality_reduction heading\n",
    "    markdown_text += \"# `dimensionality_reduction`\\n\\n\"\n",
    "\n",
    "    # List all the files in the `dimensionality_reduction` directory\n",
    "    dimensionality_reduction_files = glob.glob(os.path.join(subcommand_dir, \"*\"))\n",
    "\n",
    "    # Open up the file with *.log\n",
    "    log_file = [x for x in dimensionality_reduction_files if x.endswith(\".log\")][0]\n",
    "    log_data = open(log_file).readlines()\n",
    "\n",
    "    # Write to markdown\n",
    "    markdown_text = write_dimensionality_reduction_log_data(log_data, markdown_text)\n",
    "    markdown_text = add_dimensionality_reduction_images(subcommand_dir, outdir_path, markdown_text)\n",
    "\n",
    "if \"annotate\" in subcommands:\n",
    "    # Get subcommand dir from index of the subcoomand\n",
    "    subcommand_dir = subcommand_dirs[subcommands.index(\"annotate\")]\n",
    "\n",
    "    # Add annotate heading\n",
    "    markdown_text += \"# `annotate`\\n\\n\"\n",
    "\n",
    "    # List all the files in the `annotate` directory\n",
    "    annotate_files = glob.glob(os.path.join(subcommand_dir, \"*\"))\n",
    "\n",
    "    # Open up the file with *.log\n",
    "    #log_file = [x for x in annotate_files if x.endswith(\".log\")][0]\n",
    "    #log_data = open(log_file).readlines()\n",
    "    \n",
    "    # Write to markdown\n",
    "    markdown_text = write_annotate_log_data(markdown_text)\n",
    "    markdown_text = add_annotate_images(subcommand_dir, outdir_path, markdown_text)\n",
    "\n",
    "    # Open up the anndata file, and add the string representation of it to the markdown\n",
    "    anndata_file = [x for x in annotate_files if x.endswith(\".h5ad\")][0]\n",
    "    adata = sc.read_h5ad(anndata_file)\n",
    "    markdown_text += adata.__repr__() + \"\\n\\n\"\n",
    "    \n",
    "# Write markdown text to file\n",
    "with open(os.path.join(outdir_path, \"summary.md\"), \"w\") as f:\n",
    "    f.write(markdown_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] This document format requires a nonempty <title> element.\n",
      "  Defaulting to 'summary' as the title.\n",
      "  To specify a title, use 'title' in metadata or --metadata title=\"...\".\n"
     ]
    }
   ],
   "source": [
    "# Convert to html\n",
    "!pandoc -s -o {os.path.join(outdir_path, \"summary.html\")} {os.path.join(outdir_path, \"summary.md\")}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Loop through and pull out this info:\n",
    "- Filtered initial cells with < 20 genes\n",
    "- Low nfeatures threshold: 500\n",
    "- High nfeatures threshold: 7000\n",
    "- Percent counts in MT threshold: 3.0\n",
    "- No gene filtering\n",
    "- Retained 3468 cells\n",
    "![Untitled](RNA%20a931d770cf4f43e0a7f57aeb8354a7fb/Untitled.png)\n",
    "'''\n",
    "\n",
    "# Add the summary stats\n",
    "markdown_text += \" - Filtered initial cells with < 20 genes\\n\"\n",
    "for line in log_data:\n",
    "    if \"Low nfeatures threshold\" in line:\n",
    "        to_add = line.split(\"INFO - \")[1].strip() + \"\\n\"\n",
    "        markdown_text += \" - \" + to_add\n",
    "    if \"High nfeatures threshold\" in line:\n",
    "        to_add = line.split(\"INFO - \")[1].strip() + \"\\n\"\n",
    "        markdown_text += \" - \" + to_add\n",
    "    if \"Percent counts in MT threshold\" in line:\n",
    "        to_add = line.split(\"INFO - \")[1].strip() + \"\\n\"\n",
    "        markdown_text += \" - \" + to_add\n",
    "    if \"Number of cells after filtering of low quality cells:\" in line:\n",
    "        to_add = line.split(\"Number of cells after filtering of low quality cells:\")[1].strip()\n",
    "        markdown_text += \" - Retained \" + to_add + \" cells\\n\"\n",
    "markdown_text += \" - No gene filtering\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Histograms of counts per cell for several genes"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Typically we see that some of the low-count cells have their counts removed, since they were background noise."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown('## Histograms of counts per cell for several genes'))\n",
    "display(Markdown('Typically we see that some of the low-count cells have '\n",
    "                    'their counts removed, since they were background noise.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 R 4.3.1 scverse",
   "language": "python",
   "name": "scverse-py39-r431"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
